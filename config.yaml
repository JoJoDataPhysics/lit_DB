pdf:
  folder_path: "./test_literature"
  extensions: [".pdf"]
  recursive_scan: false

ollama:
  url: "http://localhost:11434"
  primary_model: "mistral:7b"
  fallback_models: ["llama3.2:3b", "phi3:mini"]
  auto_install: true

analysis:
  max_topics: 5
  max_keywords_per_topic: 8
  max_keywords: 10  # Kept for backward compatibility
  chunk_size: 4000
  context_overlap: 200

output:
  format: "json"
  save_results: true
  results_folder: "./results"

setup:
  check_ollama_running: true
  install_model_on_startup: true

logging:
  level: "INFO"
  file: "./logs/app.log"

database:
  path: "./data/lit_db.sqlite"
  enable_persistence: true
  backup_json: true

vector_db:
  backend: "chromadb"
  path: "./data/chromadb"
  collection_name: "lit_documents"
  embedding_model: "all-MiniLM-L6-v2"
  enable_clustering: true
  similarity_threshold: 0.7
  chunk_overlap: 200
  max_chunk_size: 1000
